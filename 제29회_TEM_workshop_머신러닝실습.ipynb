{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1Bu5E3CU3GdZYmDt3pLXE1u_cVkZChbFP","timestamp":1720078329455}],"gpuType":"T4","authorship_tag":"ABX9TyM8k9lm2Zm1cQTu/x1lJyzW"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# 제29회 TEM 워크샵 머신러닝 실습\n","이번 시간에는 딥러닝 모델을 TEM 데이터에 적용하기 전에 일반적인 이미지를 다루는 방법과 딥러닝 모델을 설계하고 학습하는 방법을 실습을 통해 배울 예정입니다.\n","\n","## 목차\n","### I. MNIST 데이터 분류\n","\n","#### I-1. 데이터 살펴보기\n","\n","#### I-2. 모델 구축하기\n","\n","#### I-3. 모델 학습하기\n","\n","#### I-4. 모델 검증하기\n","\n","### II. CIFAR100 데이터 분류\n","\n","#### II-1. 데이터 살펴보기\n","\n","#### II-2. 모델 구축하기\n","\n","#### II-3. 모델 학습하기\n","\n","#### II-4. 모델 검증하기"],"metadata":{"id":"nt7YSTYBgzvm"}},{"cell_type":"markdown","source":["## I. MNIST 데이터 분류\n","MNIST 데이터는 0에서 9 사이의 숫자 손글씨 데이터와 라벨로 구성된 데이터로 딥러닝 입문에서 가장 많이 사용하는 데이터셋 중 하나입니다.\n","\n","이번 파트에서는 MNIST 데이터를 이용해 이미지 데이터를 전처리 하는 방법, 딥러닝 모델을 구축하는 방법, 딥러닝 모델을 이용하여 데이터를 분류하는 방법, 마지막으로 학습된 모델을 검증하는 방법까지 배워보겠습니다."],"metadata":{"id":"EqqNLj_gk4lS"}},{"cell_type":"markdown","source":["### I-1. 데이터 살펴보기"],"metadata":{"id":"uJl37VublyuR"}},{"cell_type":"markdown","source":["우선 이번 실습에서 필요한 library들을 불러옵니다.\n","\n","torch는 딥러닝 분야에서 가장 많이 사용되는 PyTorch library이며, 딥러닝 모델 구축 및 학습에 필요한 데이터셋, layer, optimizer 등을 포함하고 있습니다."],"metadata":{"id":"TMTHDCIzl4-9"}},{"cell_type":"code","source":["import numpy as np\n","import matplotlib.pyplot as plt\n","\n","import torch\n","import torch.nn as nn # layers (convolution, linear, pooling, etc.)\n","import torch.optim as optim # optimizers (SGD, Adam)\n","from torchvision import datasets # 데이터셋 (MNIST, CIFAR100)\n","from torchvision import transforms # 데이터 전처리"],"metadata":{"id":"z0NPR6kVk1ni"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["---\n","이제 저희가 사용할 MNIST 데이터를 불러옵니다.\n","\n","모델 학습에 필요한 training data와 test data로 나누어져 있으며, 처음 불러올 경우 다운로드가 필요합니다."],"metadata":{"id":"9tO3f6UFn49Q"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"5ncx-D8FQhtE"},"outputs":[],"source":["transform = transforms.ToTensor() # PIL 이미지를 torch의 tensor로 변환\n","\n","train_data = datasets.MNIST(root='./data', train=True, download=True, transform=transform) # training data\n","test_data = datasets.MNIST(root='./data', train=False, download=True, transform=transform) # test data"]},{"cell_type":"markdown","source":["---\n","데이터셋의 크기를 확인해 봅시다.\n","\n","출력 순서는 [데이터 수, 높이, 너비] 입니다."],"metadata":{"id":"GOZl8F2dolD7"}},{"cell_type":"code","source":["# tensor.size(): tensor의 크기를 반환\n","print(\"Size of training data: \", train_data.data.size())\n","print(\"\\nSize of test data: \", ### 코드 작성 ###)"],"metadata":{"id":"EgSn5_l1rgxz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["---\n","MNIST 데이터가 어떤 class로 이루어져 있는지, 그리고 라벨은 어떻게 구성되어 있는지 살펴봅시다."],"metadata":{"id":"z8YgTRt2o-Ct"}},{"cell_type":"code","source":["print(\"Classes:\", test_data.classes)\n","print(\"\\nLabels:\", test_data.targets)"],"metadata":{"id":"J6A6X4XBWV2l"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["---\n","다음으로 MNIST 데이터의 이미지들이 어떻게 구성되어 있는지 살펴봅시다.\n","\n","아래 코드를 실행하면 0에서 9까지의 이미지를 각각 10장씩 출력합니다."],"metadata":{"id":"8b83eiFMpaXW"}},{"cell_type":"code","source":["fig, ax = plt.subplots(len(test_data.classes), 10, figsize=(10, 10))\n","\n","for img_class, row in enumerate(ax):\n","    class_idx = np.where(np.array(test_data.targets) == img_class)[0]\n","    for i, plot in enumerate(row):\n","        if i == 0:\n","            plot.set_ylabel(test_data.classes[img_class])\n","        plot.set_yticks([])\n","        plot.set_xticks([])\n","        idx = class_idx[i]\n","        img = test_data.data[idx]\n","        plot.imshow(img, cmap='gray')\n","plt.tight_layout()"],"metadata":{"id":"5EiZgjwZsklp"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["---\n","데이터 살펴보기의 마지막 단계로 DataLoader를 만들어 봅시다.\n","\n","먼저 **batch**라는 개념에 대해 알아야 합니다.\n","\n","딥러닝 모델을 학습시킬 때 한 번의 가중치 업데이트를 위해 여러 개의 training data를 묶어서 사용하게 되는데, 이러한 묶음을 **batch**라고 합니다.\n","\n","**batch size**는 한 batch에 들어가는 데이터의 수를 의미합니다.\n","\n","예를 들어 데이터 수가 1000개라고 할 때 batch size가 10이면 100 개의 batch, batch size가 100이면 10개의 batch로 데이터셋이 나누어지게 됩니다.\n","\n","<center>\n","<img src = \"https://drive.google.com/uc?id=1mQOfmfIkdDNlBRrs9EWut8EM26lprzmz\" width=\"700\" /><br>\n","</center>\n","\n","DataLoader는 데이터셋을 batch 단위로 나눠주고 매번 데이터 순서를 바꿔주는 등의 역할을 합니다."],"metadata":{"id":"SlHgjt9bqUrb"}},{"cell_type":"code","source":["batch_size = 32\n","\n","train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True) # training data는 매번 데이터 순서를 섞어줌 (shuffle=True)\n","test_loader = ### 코드 작성 ###"],"metadata":{"id":"_lOKpoUY1ozr"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### I-2. 모델 구축하기"],"metadata":{"id":"aabL1inVxOjW"}},{"cell_type":"markdown","source":["이제 본격적으로 모델을 구축하는 방법에 대해 알아보겠습니다.\n","\n","우선 모델 구축에 필요한 layer들은 torch.nn library에 class 형태로 포함되어 있습니다.\n","\n","저희가 사용할 layer는 convolution, max pooling, linear, 그리고 ReLU activation 입니다."],"metadata":{"id":"jPBEj7iPxVYU"}},{"cell_type":"markdown","source":["### 1) Convolution\n","2D Convolution은 CNN의 핵심 연산으로 이미지 데이터를 다룰 때 가장 많이 사용하는 layer입니다.\n","\n","Convolution layer를 이용해 이미지에서 중요한 특징(feature)을 추출할 수 있으며, 아래와 같이 사용합니다.\n","\n","`nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding, bias)`\n","- in_channels: 입력 데이터 채널의 개수입니다. 예를 들어 MNIST와 같이 흑백 이미지면 1, 컬러 이미지면 3(RGB)이 됩니다.\n","- out_channels: 출력 데이터 채널의 개수입니다. 이는 convolution filter의 개수와 동일합니다.\n","- kernel_size: convolution filter의 크기 입니다.\n","- stride: filter의 이동 간격입니다. stride가 커지면 출력 데이터의 크기가 작아집니다.\n","- padding: 입력 데이터 가장자리에 추가되는 패딩의 크기입니다. 패딩을 추가함으로써 출력 데이터의 크기를 보존할 수 있습니다.\n","- bias: bias를 사용할지 말지에 대한 여부입니다.\n"],"metadata":{"id":"aGmL6aYSyNZH"}},{"cell_type":"markdown","source":["---\n","아래 예시 코드는 8x8 크기의 3 채널 이미지를 convolution layer에 통과시키는 코드입니다.\n","\n","출력 데이터의 사이즈는 아래 식과 같으며, 여러 파라미터를 바꾸며 출력 데이터의 크기를 확인해보세요.\n","\n","output size = (input size - kernel_size + 2 * padding) / stride + 1\n","<center>\n","<img src = \"https://drive.google.com/uc?id=1L7m0wqLDOU61hEJgytLbbDpGM6QWsl7A\" width=\"900\" /><br>\n","</center>"],"metadata":{"id":"XJ8ArZHq0uB1"}},{"cell_type":"code","source":["# 입력 데이터 크기 (batch size, channels, height, width)\n","input_size = (4, 3, 8, 8)\n","\n","# 입력 데이터 생성\n","input_data = torch.randn(input_size)\n","print(\"Input size: \", input_data.size())\n","\n","# Convolution layer 정의\n","conv = ### 코드 작성 ###\n","\n","# Convolution layer 통과하여 출력 데이터 생성\n","output_data = conv(input_data)\n","\n","# 출력 데이터 크기\n","print(\"Output size: \", output_data.size())"],"metadata":{"id":"_uPempxTxUec"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 2) Max Pooling\n","Max pooling은 feature map의 크기를 줄이는 연산들 중 하나이며, window 내에 있는 값들 중 가장 큰 값을 선택하여 정보를 압축합니다.\n","\n","Max pooling layer는 convolutin layer와 비슷하게 아래와 같이 사용합니다.\n","\n","`nn.MaxPool2d(kernel_size, stride, padding)`\n","- kernel_size: pooling window의 크기 입니다.\n","- stride: window의 이동 간격입니다. 일반적으로 kernel_size와 같게 설정합니다.\n","- padding: 입력 데이터 가장자리에 추가되는 패딩의 크기입니다."],"metadata":{"id":"ETLUDZivxuv5"}},{"cell_type":"markdown","source":["---\n","아래 예시 코드는 4x4 크기의 이미지를 max pooling layer에 통과시키는 코드입니다.\n","\n","출력 데이터의 사이즈는 convolution과 동일하게 계산할 수 있으며, 여러 파라미터를 바꾸며 출력 데이터의 크기를 확인해보세요.\n","\n","<center>\n","<img src = \"https://drive.google.com/uc?id=1qqeKnmro8vhx_aNRXb7x-h671j34C5d8\" width=\"800\" /><br>\n","</center>"],"metadata":{"id":"nIBxGeJIy-7q"}},{"cell_type":"code","source":["# 입력 데이터 생성 및 크기 확인\n","input_data = np.array([[1, 2, 8, 5], [4, 3, 7, 6], [11, 12, 14, 15], [10, 9, 13, 16]], dtype=np.float32)\n","input_data = torch.from_numpy(input_data).unsqueeze(0).unsqueeze(0)\n","print(\"Input size: \", input_data.size())\n","print(\"Input data:\\n\", input_data)\n","\n","# Max pooling layer 정의\n","pool = ### 코드 작성 ###\n","\n","# Max pooling layer 통과하여 출력 데이터 생성\n","output_data = pool(input_data)\n","\n","# 출력 데이터 확인\n","print(\"\\nOutput size: \", output_data.size())\n","print(\"Output data:\\n\", output_data)"],"metadata":{"id":"l8esXl412LGo"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 3) Linear\n","Linear는 linear transformation의 역할을 하는 layer로 fully connected layer, dense layer 등으로도 불립니다.\n","\n","Linear layer는 아래와 같이 사용합니다.\n","\n","`nn.Linear(in_features, out_features, bias)`\n","- in_features: 입력 feature의 개수입니다.\n","- out_features: 출력 feature의 개수입니다.\n","- bias: bias를 사용할지 말지에 대한 여부입니다."],"metadata":{"id":"3vxxmLsu3OLY"}},{"cell_type":"markdown","source":["---\n","아래 예시 코드는 linear layer의 사용 예시입니다.\n","\n","<center>\n","<img src = \"https://drive.google.com/uc?id=1E3_DIc-PxfTlbsdqucnNbUDkiwPI6nVP\" width=\"700\" /><br>\n","</center>"],"metadata":{"id":"FRARBsIW-pVj"}},{"cell_type":"code","source":["# 입력 데이터 생성 (batch size, in_features)\n","input_data = torch.randn(4, 5)\n","print(\"Input size: \", input_data.size())\n","\n","# LInear layer 정의\n","fc = ### 코드 작성 ###\n","\n","# Convolution layer 통과하여 출력 데이터 생성\n","output_data = fc(input_data)\n","\n","# 출력 데이터 크기\n","print(\"Output size: \", output_data.size())"],"metadata":{"id":"w8EKsEX9Fqev"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 4) ReLU\n","ReLU는 activation function 중 하나로 input 값과 0중 큰 값을 반환합니다.\n","\n","즉, ReLU Layer를 통과하면 input 값 중 양수 값만 남고 나머지는 0이 됩니다.\n","\n","ReLU layer는 아래와 같이 사용합니다.\n","\n","`nn.ReLU()`"],"metadata":{"id":"YPLbUsLRGWCm"}},{"cell_type":"markdown","source":["---\n","아래 예시 코드는 ReLU layer의 사용 예시입니다.\n","\n","<center>\n","<img src = \"https://drive.google.com/uc?id=1uRboEdV3plVjVi_lIP2zWMNAm3930PSI\" width=\"700\" /><br>\n","</center>"],"metadata":{"id":"GdU8knWQH7kY"}},{"cell_type":"code","source":["# 입력 데이터 생성 확인\n","input_data = np.array([[0.7, -1.3, 2.3, 5.6, -3.8]], dtype=np.float32)\n","input_data = torch.from_numpy(input_data)\n","print(\"Input data:\\n\", input_data)\n","\n","# ReLU layer 정의\n","relu = ### 코드 작성 ###\n","\n","# ReLU layer 통과하여 출력 데이터 생성\n","output_data = relu(input_data)\n","\n","# 출력 데이터 확인\n","print(\"Output data:\\n\", output_data)"],"metadata":{"id":"HZ6UH2HYIJ1U"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["---\n","이제 앞서 나온 layer들을 이용하여 실제로 사용할 모델을 만들어보겠습니다.\n","\n","저희가 만들 모델은 아래와 같이 CNN을 이용해서 이미지에서 feature를 추출하고, 추출된 feature를 fully connected layer에 통과시켜 모델이 이미지의 class를 예측하는 구조입니다.\n","\n","모델의 최종 출력은 해당 이미지가 각 class일 확률을 의미합니다.\n","\n","(e.g. 0일 확률 0.1, 1일 확률 0.4, ..., 9일 확률 0 -> [0.1, 0.4, ..., 0])\n","\n","** 정확히는 확률이 아닌 logit이며 이는 뒤에서 추가 설명\n","<center>\n","<img src = \"https://drive.google.com/uc?id=1kkFoWtZRmc2uhLPxnr4icwqO8iPGd8He\" width=\"800\" /><br>\n","</center>"],"metadata":{"id":"ipXOtcEzJdDO"}},{"cell_type":"markdown","source":["---\n","torch library를 이용한 딥러닝 모델들은 nn.Module의 하위 클래스를 생성하여 만들 수 있습니다.\n","\n","`__init__` method에서 모델에 사용할 layer들을 정의해주고, `__forward__` method에서는 input이 들어왔을 때 앞서 정의한 layer들을 통과하여 최종 output을 return하도록 모델을 작성합니다."],"metadata":{"id":"573r4kMcQ_sf"}},{"cell_type":"code","source":["class MODEL(nn.Module): # nn.Module의 하위 클래스\n","    # img_channels: input image의 channel 수, MNIST 데이터는 1\n","    # conv_num_features1: 첫 번째 convolution layer의 output channel 수\n","    # conv_num_features2: 두 번째 convolutino layer의 output channel 수\n","    # fc_num_features: 첫 번째 fully connected layer의 ouptut feature 수\n","    # num_class: class의 개수이자 마지막 fully connected layer의 output feature 수, MNIST 데이터는 10\n","    def __init__(self, img_channels, conv_num_features1, conv_num_features2, fc_num_features, num_class):\n","        super(MODEL, self).__init__()\n","\n","        # 첫 번째 convolution layer, kernel_size=3\n","        self.conv1 = nn.Conv2d(in_channels = img_channels,\n","                               out_channels = conv_num_features1,\n","                               kernel_size = 3,\n","                               stride = 1,\n","                               padding = 1,\n","                               bias = True)\n","        # 두 번째 convolutin layer, kernel_size=3\n","        ### 코드 작성 ###\n","\n","        # 첫 번째 fully connected layer\n","        self.fc1 = nn.Linear(conv_num_features2 * 7 * 7, fc_num_features)\n","        # 두 번째 fully connected layer\n","        ### 코드 작성 ###\n","\n","        # ReLU activation\n","        self.relu = nn.ReLU()\n","        # Max Pooling\n","        self.maxpool = nn.MaxPool2d(2, 2)\n","\n","\n","    def forward(self, x):\n","        # x.size() = (B, 1, 28, 28)\n","        x = self.conv1(x) # (B, 1, 28, 28) -> (B, C1, 28, 28)\n","        x = self.relu(x)\n","        x = self.maxpool(x) # (B, C1, 28, 28) -> (B, C1, 14, 14)\n","\n","        x = ### 코드 작성 ### # (B, C1, 14, 14) -> (B, C2, 14, 14)\n","        x = ### 코드 작성 ###\n","        x = ### 코드 작성 ### # (B, C2, 14, 14) -> (B, C2, 7, 7)\n","\n","        # tensor.view(shape): tensor를 원하는 shape으로 reshape, -1은 자동으로 shape을 지정\n","        x = x.view(len(x), -1) # (B, C2, 7, 7) -> (B, C2x7x7)\n","\n","        x = self.fc1(x) # (B, C2x7x7) -> (B, C3)\n","        x = self.relu(x)\n","\n","        x = ### 코드 작성 ### # (B, C3) -> (B, 10)\n","        return x"],"metadata":{"id":"Jy4UbYdv28cm"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["---\n","이제 모델에 사용할 hyperparameter를 설정해줍니다.\n","\n","MNIST 데이터에 맞게 `img_channels`와 `num_class`는 각각 1, 10으로 설정해주고 각 layer의 channel/feature수도 적당한 값으로 설정합니다.\n","\n","일반적으로 channel/feature 수는 2의 거듭제곱으로 지정합니다."],"metadata":{"id":"0oTOfaasWDrV"}},{"cell_type":"code","source":["img_channels = 1\n","conv_num_features1 = 32\n","conv_num_features2 = 64\n","fc_num_features = 64\n","num_class = 10"],"metadata":{"id":"Mc0LCSm43Y8U"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["---\n","cpu와 gpu (cuda) 중 어떤 device를 사용할지 아래와 같이 정의합니다.\n","\n","또한 앞서 설정한 hyperparameter로 모델을 정의합니다."],"metadata":{"id":"Zu3wO_B6WmGz"}},{"cell_type":"code","source":["# device 정의\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# 모델 정의\n","model = ### 코드 작성 ###\n","model = model.to(device)"],"metadata":{"id":"u7drnYHJ3lgf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### I-3. 모델 학습하기"],"metadata":{"id":"QsDpzjvTXEQo"}},{"cell_type":"markdown","source":["이제 모델을 학습할 차례입니다.\n","\n","학습에 앞서 몇 가지 hyperparameter를 설정합니다.\n","\n","Epoch은 학습 데이터를 총 몇 번 반복하여 학습할 것인지 결정하는 hyperparameter입니다.\n","\n","Learning rate는 모델의 가중치(weight) 업데이트의 정도를 결정하는 hyperparameter입니다.\n","\n","Learning rate가 크면 loss가 빠르게 수렴하지만 학습이 불안정할 수 있으며, 반대로 작을 경우 학습은 안정적이지만 최적값에 다다르기까지 시간이 매우 오래 걸릴 수 있으므로 적절한 값으로 설정해줍니다.\n"],"metadata":{"id":"UHeZlNpfXJii"}},{"cell_type":"code","source":["# Epoch 수 설정\n","EPOCH = 10\n","# Learning rate 설정\n","learning_rate = 0.001"],"metadata":{"id":"4au8hTIHWbbz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["---\n","다음으로 optimizer와 loss를 정의해줍니다.\n","\n","Optimizer는 일반적으로 많이 사용하는 Adam optimizer를 사용하며, 업데이트할 parameter와 learning rate를 input으로 받습니다."],"metadata":{"id":"UJm-y8c0bo7a"}},{"cell_type":"markdown","source":["---\n","Loss는 classification에서 사용하는 cross entropy loss를 사용하며, 아래와 같은 수식으로 정의됩니다.\n","\n","$$H(P, Q) = -∑p_i\\log(q_i)$$\n","\n","여기서 𝑃 는 one hot 형태의 label 이며 𝑄는 모델이 예측한 확률이라고 생각할 수 있습니다.\n","\n","e.g. label = 5 ->\n","\n","𝑃=[0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n","\n","𝑄=[0.1, 0, 0, 0, 0.7, 0.2, 0, 0, 0]\n","\n","𝐻=-log(0.7)=0.3567"],"metadata":{"id":"X6cmymdIhDsb"}},{"cell_type":"markdown","source":["---\n","따라서 cross entropy를 계산하기 위해서는 label을 모두 one hot 형태로 바꿔주고 모델의 출력인 logit을 softmax를 이용하여 확률값으로 바꿔주어야 합니다.\n","\n","하지만 `torch.nn`에서 제공하는 `CrossEntropyLoss`를 사용할 경우 이를 자동으로 수행해줍니다."],"metadata":{"id":"umDH1dBthv7A"}},{"cell_type":"code","source":["# Optimizer 정의\n","optimizer = optim.Adam(params = model.parameters(), lr = learning_rate)\n","\n","# Loss function 정의\n","criterion = nn.CrossEntropyLoss()"],"metadata":{"id":"ci1wCubv35Za"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["---\n","이제 아래 코드를 통해 모델을 직접 학습해 봅시다."],"metadata":{"id":"P2KYML3CiU6B"}},{"cell_type":"code","source":["# Epoch 수만큼 학습 반복\n","for epoch in range(1, EPOCH + 1):\n","    print(f\"EPOCH : {epoch}\")\n","\n","    # 각 epoch 별 loss와 accuracy\n","    train_loss = 0.0\n","    train_acc = 0.0\n","\n","    for images, labels in train_loader:\n","        # 학습에 사용할 tensor들은 모두 device로 보내줌\n","        images = images.to(device)\n","        labels = labels.to(device)\n","\n","        # Model의 output은 logit\n","        logits = model(images)\n","\n","        # Cross entropy loss 계산\n","        loss = criterion(logits, labels)\n","\n","        # Optimizer gradient 초기화\n","        optimizer.zero_grad()\n","\n","        # Gradient 계산\n","        loss.backward()\n","\n","        # Weight update\n","        optimizer.step()\n","\n","        train_loss += loss.item() * images.size(0)\n","\n","        _, prediction = logits.max(1)\n","\n","        train_acc += (labels == prediction).sum().item()\n","\n","    train_loss = train_loss / len(train_loader.dataset)\n","    train_acc = train_acc / len(train_loader.dataset) * 100\n","    print(\"| Training Loss : {:.3f} | Training Accuracy: {:.3f} % |\".format(train_loss, train_acc))"],"metadata":{"id":"tHqzbEfD6X9I"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### I-4. 모델 검증하기"],"metadata":{"id":"askXcmxsOd0v"}},{"cell_type":"markdown","source":["마지막으로 학습된 모델을 검증해보겠습니다.\n","\n","모델 검증은 학습에 사용되지 않은, 즉 모델이 보지 못한 test data를 이용하여 진행합니다.\n","\n","아래 코드를 실행시키면 test data에 대한 accuracy를 구할 수 있습니다."],"metadata":{"id":"preVAoaYOiem"}},{"cell_type":"code","source":["model.eval()\n","\n","test_acc = 0\n","predictions = []\n","for images, labels in test_loader:\n","    images = images.to(device)\n","    labels = labels.to(device)\n","\n","    logits = model(images)\n","\n","    _, prediction = logits.max(1)\n","\n","    test_acc += (labels == prediction).sum().item()\n","\n","    predictions.append(prediction.detach().cpu().numpy())\n","\n","predictions = np.concatenate(predictions)\n","\n","test_acc = test_acc / len(test_loader.dataset) * 100\n","print(\"| Test Accuracy: {:.3f} % |\".format(test_acc))"],"metadata":{"id":"0sCftLnSL_Kf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["---\n","각 class 별로 10개의 이미지와 그에 대해 모델이 예측한 class를 출력하여 확인해봅니다."],"metadata":{"id":"XrsASoNVO2fU"}},{"cell_type":"code","source":["fig, ax = plt.subplots(len(test_data.classes), 10, figsize=(10, 10))\n","\n","for img_class, row in enumerate(ax):\n","    class_idx = np.where(np.array(test_data.targets) == img_class)[0]\n","    for i, plot in enumerate(row):\n","        if i == 0:\n","            plot.set_ylabel(test_data.classes[img_class])\n","        plot.set_yticks([])\n","        plot.set_xticks([])\n","        idx = class_idx[i]\n","        plot.set_xlabel(predictions[idx])\n","        img = test_data.data[idx]\n","        plot.imshow(img, cmap='gray')\n","plt.tight_layout()"],"metadata":{"id":"S6NSzT5hzUwE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["---\n","MNIST data classification은 마무리 되었습니다.\n","\n","시간 여유가 있으시다면 여러 hyperparameter(batch size, learning rate, epoch 등)들을 바꿔서 결과를 비교해보세요."],"metadata":{"id":"FuAfPEIZPwR4"}},{"cell_type":"markdown","source":["## II. CIFAR100 데이터 분류\n","CIFAR100 데이터는 사과, 물고기, 아기 등 총 100가지 class의 컬러 이미지들로 구성된 데이터입니다.\n","\n","이번 파트에서는 MNIST 데이터보다 좀 더 복잡한 CIFAR100 데이터를 이용해 classification을 진행해 보겠습니다."],"metadata":{"id":"4vfPVxQbQFqe"}},{"cell_type":"markdown","source":["### II-1. 데이터 살펴보기"],"metadata":{"id":"1sB32i5sRzkA"}},{"cell_type":"markdown","source":["MNIST 데이터와 마찬가지로 데이터를 다운로드하고 불러옵니다.\n","\n","조금 다른 점은 train data에 대해서는 무작위로 좌우 반전 (`transforms.RandomHorizontalFlip()`)을 적용하여 data augmentation 효과를 줍니다."],"metadata":{"id":"wV79DIkZR_ck"}},{"cell_type":"code","source":["train_transform = transforms.Compose([\n","    transforms.RandomHorizontalFlip(),\n","    transforms.ToTensor(),\n","])\n","\n","test_transform = transforms.Compose([\n","    transforms.ToTensor(),\n","])\n","\n","train_data = datasets.CIFAR100(root='./data', train=True, download=True, transform=train_transform)\n","test_data = datasets.CIFAR100(root='./data', train=False, download=True, transform=test_transform)"],"metadata":{"id":"Rs7X4bjBSHrh"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["---\n","데이터셋의 크기를 확인해 봅시다.\n","출력 순서는 [데이터 수, 높이, 너비, 채널 수] 입니다."],"metadata":{"id":"slh3HoaKTm3S"}},{"cell_type":"code","source":["print(\"Size of training data: \", train_data.data.shape)\n","print(\"\\nSize of test data: \", test_data.data.shape)"],"metadata":{"id":"pPs_oJmgVUFv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["---\n","CIFAR100 데이터가 어떤 class를 포함하고 있는지 확인합니다."],"metadata":{"id":"mecS54IhT0uJ"}},{"cell_type":"code","source":["print(\"Classes:\", test_data.classes)"],"metadata":{"id":"RZi9LtByWaDK"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["아래 코드를 실행하여 100개의 class 중 10개의 class에 대해서 각 10장씩 이미지를 확인해 봅시다."],"metadata":{"id":"PO8Q4hg3T77t"}},{"cell_type":"code","source":["fig, ax = plt.subplots(10, 10, figsize=(10, 10))\n","\n","for img_class, row in enumerate(ax):\n","    class_idx = np.where(np.array(test_data.targets) == img_class)[0]\n","    for i, plot in enumerate(row):\n","        if i == 0:\n","            plot.set_ylabel(test_data.classes[img_class])\n","        plot.set_yticks([])\n","        plot.set_xticks([])\n","        idx = class_idx[i]\n","        img = test_data.data[idx]\n","        plot.imshow(img, cmap='gray')\n","plt.tight_layout()"],"metadata":{"id":"T9iwiPInlDsn"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["---\n","Batch size를 설정하고 DataLoader를 만들어줍니다."],"metadata":{"id":"4n7ISK7UUSuR"}},{"cell_type":"code","source":["batch_size = 32\n","\n","train_loader = ### 코드 작성 ###\n","test_loader = ### 코드 작성 ###"],"metadata":{"id":"QZtvw10tnICN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### II-2. 모델 구축하기"],"metadata":{"id":"fLmDk2hoUa7b"}},{"cell_type":"markdown","source":["MNIST와 마찬가지로 CIFAR100 데이터를 위한 모델을 구축해 봅시다.\n","\n","앞에서 사용한 모델과 거의 똑같지만 한 가지 다른 점은 convolution layer를 추가하여 더 깊은 CNN 구조를 사용한다는 것입니다.\n","<center>\n","<img src = \"https://drive.google.com/uc?id=1SPkFGnHxNH8Y7YpuS7dNm-veRw_dygBI\" width=\"900\" /><br>\n","</center>"],"metadata":{"id":"1XiW6MpfUh7Q"}},{"cell_type":"code","source":["class MODEL(nn.Module):\n","    # img_channels: input image의 channel 수, MNIST 데이터는 1\n","    # conv_num_features1: 첫 번째 convolution layer의 output channel 수\n","    # conv_num_features2: 두 번째 convolutino layer의 output channel 수\n","    # conv_num_features3: 세 번째 convolutino layer의 output channel 수\n","    # fc_num_features: 첫 번째 fully connected layer의 ouptut feature 수\n","    # num_class: class의 개수이자 마지막 fully connected layer의 output feature 수, MNIST 데이터는 10\n","    def __init__(self, img_channels, conv_num_features1, conv_num_features2, conv_num_features3, fc_num_features, num_class):\n","        super(MODEL, self).__init__()\n","\n","        # 첫 번째 convolution layer, kernel_size=3\n","        self.conv1 = ### 코드 작성 ###\n","        # 두 번째 convolutin layer, kernel_size=3\n","        self.conv2 = ### 코드 작성 ###\n","        # 세 번째 convolutin layer, kernel_size=3\n","        self.conv3 = ### 코드 작성 ###\n","\n","        # 첫 번째 fully connected layer\n","        self.fc1 = ### 코드 작성 ###\n","        # 두 번째 fully connected layer\n","        self.fc2 = ### 코드 작성 ###\n","\n","        # ReLU activation\n","        self.relu = nn.ReLU()\n","        # Max Pooling\n","        self.maxpool = nn.MaxPool2d(2, 2)\n","\n","\n","    def forward(self, x):\n","         # x.size() = (B, 3, 32, 32)\n","        x = ### 코드 작성 ### # (B, 3, 32, 32) -> (B, C1, 32, 32)\n","        x = ### 코드 작성 ###\n","        x = ### 코드 작성 ### # (B, C1, 32, 32) -> (B, C1, 16, 16)\n","\n","        x = ### 코드 작성 ### # (B, C1, 16, 16) -> (B, C2, 16, 16)\n","        x = ### 코드 작성 ###\n","        x = ### 코드 작성 ### # (B, C2, 16, 16) -> (B, C2, 8, 8)\n","\n","        x = ### 코드 작성 ### # (B, C2, 8, 8) -> (B, C3, 8, 8)\n","        x = ### 코드 작성 ###\n","        x = ### 코드 작성 ### # (B, C3, 8, 8) -> (B, C3, 4, 4)\n","\n","        x = x.view(len(x), -1) # (B, C3, 4, 4) -> (B, C3x4x4)\n","\n","        x = ### 코드 작성 ### # (B, C3x4x4) -> (B, C4)\n","        x = ### 코드 작성 ###\n","\n","        x = ### 코드 작성 ### # (B, C4) -> (B, 100)\n","        return x"],"metadata":{"id":"nkj40-t2nN7l"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["---\n","Hyperparameter를 설정해줍니다.\n","\n","CIFAR100 이미지는 컬러 이미지이므로 `img_channels`는 3 (RGB), `num_class`는 100으로 설정해줍니다."],"metadata":{"id":"hPx_rt27X0f4"}},{"cell_type":"code","source":["img_channels = 3\n","conv_num_features1 = 32\n","conv_num_features2 = 64\n","conv_num_features3 = 128\n","fc_num_features = 128\n","num_class = 100"],"metadata":{"id":"_fw0Up2LoOc4"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["---\n","Device와 모델도 정의해줍니다."],"metadata":{"id":"cxVpBhmyYQxL"}},{"cell_type":"code","source":["# device 정의\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# 모델 정의\n","model = ### 코드 작성 ###\n","model = model.to(device)"],"metadata":{"id":"l1nzzhNxoihX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### II-3. 모델 학습하기"],"metadata":{"id":"7nhwiKSUYUvc"}},{"cell_type":"markdown","source":["모델 학습은 이전과 동일하게 hyperparameter를 설정해주고 진행합니다."],"metadata":{"id":"7-pZySP0Yc0B"}},{"cell_type":"code","source":["# Epoch 수 설정\n","EPOCH = 100\n","# Learning rate 설정\n","learning_rate = 0.001"],"metadata":{"id":"he7USMxUYZDZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["---\n","마찬가지로 Adam optimizer와 cross entropy loss를 사용합니다."],"metadata":{"id":"APys2KB1Ylvy"}},{"cell_type":"code","source":["# Optimizer 정의\n","optimizer = optim.Adam(params = model.parameters(), lr = learning_rate)\n","\n","# Loss function 정의\n","criterion = nn.CrossEntropyLoss()"],"metadata":{"id":"rE6bK1oior0C"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["---\n","모델을 학습합니다."],"metadata":{"id":"DreSYmwyYwq2"}},{"cell_type":"code","source":["for epoch in range(1, EPOCH + 1):\n","    print(f\"EPOCH : {epoch}\")\n","\n","    train_loss = 0.0\n","    train_acc = 0.0\n","\n","    for images, labels in train_loader:\n","        ### 코드 작성 ###\n","\n","        train_loss += loss.item() * images.size(0)\n","\n","        _, prediction = logits.max(1)\n","\n","        train_acc += (labels == prediction).sum().item()\n","\n","    train_loss = train_loss / len(train_loader.dataset)\n","    train_acc = train_acc / len(train_loader.dataset) * 100\n","    print(\"| Training Loss : {:.3f} | Training Accuracy: {:.3f} % |\".format(train_loss, train_acc))"],"metadata":{"id":"aFBD9THYovfh"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### II-4. 모델 검증하기"],"metadata":{"id":"nK5bH_u-Y0rn"}},{"cell_type":"markdown","source":["마찬가지로 test set을 이용해 모델을 검증해봅시다.\n","\n","앞서 MNIST 데이터보다 복잡한 CIFAR100 데이터를 사용했을 때 결과가 어떻게 달라졌는지 비교해봅니다."],"metadata":{"id":"cRrjccE1Y3jM"}},{"cell_type":"code","source":["model.eval()\n","\n","test_acc = 0\n","predictions = []\n","for images, labels in test_loader:\n","    images = images.to(device)\n","    labels = labels.to(device)\n","\n","    logits = model(images)\n","\n","    _, prediction = logits.max(1)\n","\n","    test_acc += (labels == prediction).sum().item()\n","\n","    predictions.append(prediction.detach().cpu().numpy())\n","\n","predictions = np.concatenate(predictions)\n","\n","test_acc = test_acc / len(test_loader.dataset) * 100\n","print(\"| Test Accuracy: {:.3f} % |\".format(test_acc))"],"metadata":{"id":"BRL_2s8srmZM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["---\n","MNIST 데이터와 달리 training accuracy에 비해 test accuracy가 아주 낮게 나오는 것을 볼 수 있습니다.\n","\n","이는 모델이 training data의 정보만을 외워서 학습하여 다른 데이터가 들어왔을 때 제대로 예측하지 못하기 때문입니다.\n","\n","이러한 현상을 과적합(overfitting)이라고 합니다.\n","\n","이를 방지하기 위해서는 여러 hyperparameter의 조절, data augmentation, 별도의 validation data을 이용한 ealry stopping 등이 필요합니다.\n"],"metadata":{"id":"OilIJBSBZDF2"}},{"cell_type":"markdown","source":["---\n","각 class 별로 10개의 이미지와 그에 대해 모델이 예측한 class를 출력하여 확인해봅니다."],"metadata":{"id":"WyhQCo3Tf69j"}},{"cell_type":"code","source":["fig, ax = plt.subplots(10, 10, figsize=(10, 10))\n","\n","for img_class, row in enumerate(ax):\n","    class_idx = np.where(np.array(test_data.targets) == img_class)[0]\n","    for i, plot in enumerate(row):\n","        if i == 0:\n","            plot.set_ylabel(test_data.classes[img_class])\n","        plot.set_yticks([])\n","        plot.set_xticks([])\n","        idx = class_idx[i]\n","        plot.set_xlabel(test_data.classes[predictions[idx]])\n","        img = test_data.data[idx]\n","        plot.imshow(img, cmap='gray')\n","plt.tight_layout()"],"metadata":{"id":"aUS6A_LOr3wP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["---\n","이로써 CIFAR100 data classification도 마무리되었습니다.\n","\n","다른 hyperparameter를 바꾸었을 때 결과가 어떻게 달라지는지 확인해보세요."],"metadata":{"id":"MQAoDCsiZHZy"}}]}